{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy import interp\n",
    "import pandas.core.algorithms as algos \n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meta-data from clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = pd.read_clipboard(header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "droplist1 = pd.read_clipboard(header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/data2/GMC/sample_dev_cln.csv',header= None)#,converters = {'.':np.nan})#,nrows=5000)\n",
    "df1.columns = col[0].values\n",
    "df1=df1.set_index(df1.Seqnum)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df1 = df1.drop(droplist1,1)\n",
    "print df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.replace('.',np.nan)\n",
    "df1 = df1.apply(lambda x: pd.to_numeric(x, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperate numeric and non-numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def var_classfication(data):\n",
    "    var_object = data.dtypes[data.dtypes==object].index\n",
    "    var_date = [x for x in var_object if type(x)=='str' and x[-3:]=='dte' ]\n",
    "    var_nonnum = [x for x in var_object if x not in var_date]\n",
    "    var_num = data.dtypes[data.dtypes!=object].index\n",
    "    return var_date,var_nonnum,var_num\n",
    "\n",
    "var_date,var_nonnum,var_num = var_classfication(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print var_nonnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category variables with 10+ levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(df1[var_nonnum]):\n",
    "        ct = df1[j].nunique()\n",
    "        if ct >10:\n",
    "            print j,ct#i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,j in enumerate(df1[var_nonnum]):\n",
    "        ct = df1[j].nunique()\n",
    "        if ct <=10:\n",
    "            print j,ct#i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sic2d(row_):\n",
    "    if row_=='    ' or row_!=row_ or row_ == '' or row_ == ' ':\n",
    "        return 11\n",
    "    else:\n",
    "        row = int(row_)/100\n",
    "        #if row.isin(43, 90,91,92,93,94,95,96,97,98):\n",
    "        if row >  0 and row<=9:\n",
    "            return 1\n",
    "        elif row<=14:\n",
    "            return 2\n",
    "        elif row<-17:\n",
    "            return 3\n",
    "        elif row<=39:\n",
    "            return 4\n",
    "        elif row<=49:\n",
    "            return 5\n",
    "        elif row<=51:\n",
    "            return 6\n",
    "        elif row<=59:\n",
    "            return 7\n",
    "        elif row<=67:\n",
    "            return 8\n",
    "        elif row<=89:\n",
    "            return 9\n",
    "        elif row<=97:\n",
    "            return 10\n",
    "        else:\n",
    "            return 11\n",
    "df1['sic2d'] = df1['SIC4'].map(sic2d)\n",
    "def age(df):\n",
    "    df.YRSTART = df.YRSTART.replace(to_replace=[' ','  ','   ','    '], value=2016)\n",
    "    df.YRSTART = df.YRSTART.astype(float)\n",
    "    df['start_age'] = 2016 - df['YRSTART'] \n",
    "    df.loc[df.start_age>200,:].start_age = 200\n",
    "    return df\n",
    "age(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull all category variables with < 10 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_nonnum.remove('BUSINESSDATE')\n",
    "var_nonnum.remove('BUSINESS_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummylist1 = [j for i,j in enumerate(df1[var_nonnum]) if df1[j].nunique()<=10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dummy_matrix=pd.DataFrame()\n",
    "nan_map = lambda x: 0 if x!= x else x\n",
    "for j in dummylist1:\n",
    "    dummy = pd.get_dummies(df1[j].map(nan_map),prefix=j)\n",
    "    dummy_matrix = pd.concat([dummy_matrix,dummy],1)\n",
    "dummy_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2=pd.concat([df1[var_num],dummy_matrix],1)\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.NEW_BAD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#droplist2 = [i for i in df3.columns.values if i[4:15]=='PDUE_BUCKET']\n",
    "df3 = df3.drop(droplist2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y= df3['NEW_BAD']\n",
    "X = df3.drop(['NEW_BAD','SEGMENT_PM2016'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size=0.3, random_state=3243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alternatively, impute to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "imp = Imputer(missing_values='NaN', strategy='median')\n",
    "imp.fit(Xtrain)\n",
    "Xtrain=imp.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a quick random forest model to see if top predictors makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(     n_estimators=100, \n",
    "                                    #class_weight='balanced_subsample',\n",
    "                                    max_depth = 80,\n",
    "                                    min_samples_leaf=500,\n",
    "                                    #max_features=100,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "model = forest\n",
    "\n",
    "import time\n",
    "start = time.time()    \n",
    "model.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba= model.predict_proba(X_train)\n",
    "print roc_auc_score(y_train,proba[:,1])\n",
    "proba= model.predict_proba(X_test)\n",
    "print  roc_auc_score(y_test,proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "feature_importance = model.feature_importances_\n",
    "cols = X_train.columns\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance )#/ feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "top_sorted_idx = sorted_idx[:20]\n",
    "pos = np.arange(top_sorted_idx.shape[0]) + .5\n",
    "#fig = plt.figure() \n",
    "plt.barh(pos, feature_importance[top_sorted_idx][::-1], align='center')\n",
    "plt.yticks(pos, cols[top_sorted_idx][::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "#plt.savefig(\"var_importance1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_sorted_idx = sorted_idx[:50]\n",
    "t1 = cols[top_sorted_idx].values\n",
    "t2 = feature_importance[top_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum([i > 0.0 for i in feature_importance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(feature_importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv('/data2/GMC/sample_dev_cln2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_table('sample_oot_meta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "col = meta.Variable.values\n",
    "meta['pd_type'] = meta['Type'].map({'Num':np.float,'Char':str})\n",
    "meta.loc[meta['Format'].astype(str).map(lambda x:x[:4])=='MMDD','pd_type'] = str\n",
    "converter1 = meta.pd_type.to_dict()\n",
    "meta.pd_type = str\n",
    "converter2 = meta.pd_type.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###holdout_sample\n",
    "start = time.time()    \n",
    "dfh = pd.read_csv('/data2/GMC/sample_cln.csv',na_values=['.'],header= None,converters =converter2)\n",
    "dfh.columns = col\n",
    "dfh=dfh.set_index(dfh.Seqnum)\n",
    "dfh.shape\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#keeplist= col[0][~col[0].isin(droplist2)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()  \n",
    "dfh = dfh.replace('.',np.nan)\n",
    "dfh = dfh.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "#df_h.fillna('0',inplace=True)\n",
    "#df_h = df_h.replace(' ','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_short = pd.read_csv('/data2/GMC/sample_dev_cln2.csv',nrows = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var_classfication(data):\n",
    "    var_object = data.dtypes[data.dtypes==object].index\n",
    "    var_date = [x for x in var_object if type(x)=='str' and x[-3:]=='dte' ]\n",
    "    var_nonnum = [x for x in var_object if x not in var_date]\n",
    "    var_num = data.dtypes[data.dtypes!=object].index\n",
    "    return var_date,var_nonnum,var_num\n",
    "\n",
    "var_date,var_nonnum,var_num = var_classfication(dfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummylist2 = [j for i,j in enumerate(dfh[var_nonnum]) if dfh[j].nunique()<=10]\n",
    "dummylist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variable\n",
    "dummy_matrix=pd.DataFrame()\n",
    "nan_map = lambda x: 0 if x!= x else x\n",
    "for j in dummylist2:\n",
    "    dummy = pd.get_dummies(dfh[j].map(nan_map),prefix=j)\n",
    "    dummy_matrix = pd.concat([dummy_matrix,dummy],1)\n",
    "dummy_matrix.head()\n",
    "\n",
    "df_h2=pd.concat([dfh[var_num],dummy_matrix],1)\n",
    "print df_h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print set(df_h2.columns) - set(df1_short.columns)\n",
    "print set(df1_short.columns) - set(df_h2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if any difference in attribute list between train and validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "misscolumn = (set(df1_short.columns) - set(df_h2.columns)) \n",
    "for a in misscolumn:\n",
    "             df_h2[a]=0\n",
    "df_h2 = df_h2[df1_short.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "droplist2 = [i for i in df_h2.columns.values if i[4:15]=='PDUE_BUCKET']\n",
    "df_h2 = df_h2.drop(droplist2,1)\n",
    "df_h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_h2.to_csv('/data2/GMC/sample_oot_cln2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
